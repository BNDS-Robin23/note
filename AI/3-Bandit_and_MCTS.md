# Bandit and MCTS
## 现实语言中的随机数算法
```c++
//c++
#include<stdlib.h>
srand(seed);
int r = rand()
```
```java
//java
import java.util.Random;
Random rnd = new Random(seed);
int r = rnd.nextInt(upper);
```
使用seed的好处在于能够在需要时重现上一次的随机数情况。

## Bandit算法
### UCB算法
1. 先对每一个臂都尝试一遍
2. 按照如下公式计算每个臂的分数，然后选择分数最大的臂
$$\frac{Q(k)}{N(k)}+\sqrt{\frac{\ln N(k)_{total}}{N(k)}}$$
其中，Q(k)为这个臂所有被试时的分数之和，N(k)为被试次数，N(k)_total是全局已尝试次数。
3. 观察选择结果，更新N(k)和Q(k)，继续下一步选择。

### $\epsilon-greddy$
1. 选择一个(0, 1)之间较小的数为$\epsilon$
2. 每次以概率$\epsilon$在所有臂中随机选择一个，以$1-\epsilon$在所有臂中选择到目前为止平均收益最大的那个臂
3. $\epsilon$的值可以帮助我们控制对exploit和explore的偏好程度。

## 蒙特卡洛树搜索
1. 首先根据bandit在已经被完全展开的节点中选择一条路径，直到遇到的未被完全展开的节点（叶节点）。
2. 到达叶节点（边缘节点）后，按照一定的策略选择叶节点的某个子节点，对这个新的子节点进行roll out（一直随机走到底），得出这条随机路径的值，然后对这整个路径上的之前用bandit选择的点、边缘未被展开的叶节点、叶节点往下我们选择的那个节点的bandit值进行反向更新。
3. 重新在目前已经被完全展开的节点中根据bandit选择路径，步骤同1.
4. 注意，由于任何一个节点在未被访问之前N(k)=Q(k)=0，其Bandit值为无穷大。路径会倾向于选择这个没被访问过的点。因此蒙特卡洛树搜索总是倾向于搜索完这一层的所有节点。
5. 有的时候可以给UCB算法中添加平滑项和随机数，用于解决4中的除0问题和解决有多个待选支点相同的问题。
**如果能有无穷次尝试，蒙特卡洛树搜索得出的路径是最优的。和$\alpha$-$\beta$剪枝相比，不需要去定义启发式函数。对于启发式函数很难定义而问题结果定义明确的问题，比如围棋，蒙特卡洛树搜索很适合。**
+ 应用场景：围棋（蒙特卡洛博弈树搜索）

## search in belief
+ 在状态没有办法进行完全观测的情况下，可以根据对于状态的推演来推断出当前可能的状态集合。把这种集合叫做belief，然后对belief进行搜索。

